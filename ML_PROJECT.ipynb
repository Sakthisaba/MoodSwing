import os
import keras
import numpy as np
from keras import optimizers, models, layers
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D, BatchNormalization, Activation

from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
!pip install keras
!unzip "/content/drive/MyDrive/train2.zip"
!unzip "/content/drive/MyDrive/validation2.zip"
train_dir = "/content/train1/train"
val_dir = "/content/validation1/validation"
from PIL import Image
from google.colab import drive
drive.mount('/content/drive')
classes = dict()
reverse_classes = dict()
count = 0
for folder in os.listdir("/content/train1/train"):
    classes[folder] = count
    reverse_classes[count] = img
    count = count + 1

reverse_classes[4]
classes
BATCH_SIZE = 64

    
train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=30,
                                   shear_range=0.3,
                                   width_shift_range=0.3,
                                   height_shift_range=0.3,
                                   zoom_range=0.3,
                                   horizontal_flip=True,
                                   fill_mode="nearest")
val_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(train_dir,
                                                    color_mode='grayscale',
                                                    target_size=(48, 48),
                                                    batch_size=BATCH_SIZE,
                                                    class_mode='categorical',
                                                    shuffle=True)

val_generator = val_datagen.flow_from_directory(val_dir,
                                                color_mode='grayscale',
                                                target_size=(48, 48),
                                                batch_size=BATCH_SIZE,
                                                class_mode='categorical',
                                                shuffle=True)


num_train = 24256
num_val = 3006

model = models.Sequential([
    # Block 1
    # Leave strides as default since images are small
    Conv2D(32, (3, 3), padding="same", kernel_initializer="he_normal", input_shape=(48, 48, 1)),
    BatchNormalization(),
    Activation("relu"),
    Conv2D(32, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    MaxPool2D((2, 2)),
    Dropout(0.25),

    # Block 2
    Conv2D(64, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    Conv2D(64, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    MaxPool2D((2, 2)),
    Dropout(0.25),

    # Block 3dsgdh
    Conv2D(128, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    Conv2D(128, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    MaxPool2D((2, 2)),
    Dropout(0.25),

    # Block 4
    Conv2D(256, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    Conv2D(256, (3, 3), padding="same", kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    MaxPool2D((2, 2)),
    Dropout(0.25),

    # Block 5
    Flatten(),
    Dense(64, kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    Dropout(0.5),

    # Block 6
    Dense(128, kernel_initializer="he_normal"),
    BatchNormalization(),
    Activation("relu"),
    Dropout(0.5),

    # Output layer
  
    Dense(5, kernel_initializer="glorot_normal", activation="softmax")
])
model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])
Checkpoint = ModelCheckpoint("Emotion_Detector.h5",
                             monitor="val_loss",
                             mode="min",
                             save_best_only=True,
                             verbose=1)
Early_Stopping = EarlyStopping(monitor="val_loss",
                              min_delta=0,
                              patience=3,
                              verbose=1,
                              restore_best_weights=True)
Reduce_LR = ReduceLROnPlateau(monitor="val_loss",
                              factor=0.2, # Decrease by 20% each time
                              patience=3,
                              verbose=1,
                              min_delta=0.0001)
history = model.fit(train_generator, 
                    steps_per_epoch=num_train//BATCH_SIZE,
                    epochs=25,
                    callbacks=[Checkpoint, Early_Stopping, Reduce_LR],
                    validation_data=val_generator,
                    validation_steps=num_val//BATCH_SIZE)

model.save("Emotion_Detector.h5")
model.summary()
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(11)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
# The model predicted the sample image accurately
image = Image.open("/content/WIN_20220611_12_00_24_Pro.jpg")
image = image.resize((48, 48))
arr = np.array(image)
x_data = [arr]
x_data = np.array(x_data, dtype = "float32")
x_data = x_data.reshape((len(x_data), 48, 48, 1))
x_data /= 255
pred_array = model.predict(x_data)
result = reverse_classes[np.argmax(pred_array)]
t =lst[np.argmax(pred_array)]
print(f" the image is of {t}")

# to display the image 
import matplotlib.pyplot as plt 
plt.imshow(image)
plt.title("input image")
plt.show()
pred_array
